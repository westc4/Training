{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — AudioCraft training (compression/debug)\n",
    "Run Dora training on the prepared `fma_small_mini` dataset and capture logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Single switch for all paths (defaults to your new location)\n",
    "BASE_DIR = Path(os.environ.get(\"WORKSPACE_DIR\", \"/root/workspace\"))\n",
    "\n",
    "AUDIOCRAFT_REPO_DIR = BASE_DIR / \"audiocraft\"\n",
    "EXPERIMENTS_DIR     = BASE_DIR / \"experiments\" / \"audiocraft\"\n",
    "\n",
    "#DSET = \"audio/all_data\"\n",
    "DSET = \"audio/all_data\"\n",
    "#SOLVER = \"compression/debug\"\n",
    "SOLVER = \"compression/encodec_musicgen_32khz\"\n",
    "\n",
    "#SEGMENT_SECONDS = 10\n",
    "SEGMENT_SECONDS = 60\n",
    "BATCH_SIZE = 4  # Lower to 4 if training on 60s increase to 32 for 10s\n",
    "#BATCH_SIZE = 64  # Increased from 8 to improve GPU utilization\n",
    "\n",
    "# Auto-pick workers: reduce to 4-6 to avoid CPU contention\n",
    "_cpu_count = os.cpu_count() or 32\n",
    "# NUM_WORKERS = min(16, max(8, _cpu_count // 4))   # 8–16 is usually the sweet spot\n",
    "# NUM_WORKERS = 16 # this worked well on v84 cpu\n",
    "NUM_WORKERS = 16 # this worked well on v84 cpu\n",
    "\n",
    "UPDATES_PER_EPOCH = 1000\n",
    "VALID_NUM_SAMPLES = 10\n",
    "GENERATE_EVERY = \"null\"  # Disable automatic generation during training\n",
    "EVALUATE_EVERY = \"null\"  # Disable automatic evaluation during training\n",
    "AUTOCAST = True\n",
    "# NUM_THREADS = 16  # Set number of threads for PyTorch operations\n",
    "NUM_THREADS = 8  # Set number of threads for PyTorch operations\n",
    "#MP_START_METHOD = \"fork\" # Use 'fork' to reduce overhead on Linux systems\n",
    "#MP_START_METHOD = \"fork\" # Alternative method if issues arise with 'fork'\n",
    "MP_START_METHOD = \"spawn\" # Alternative method if issues arise with 'fork'\n",
    "DATASET_BATCH_SIZE = 2 # Batch size for multi gpu setup\n",
    "DATASET_NUM_SAMPLES = 2000\n",
    "CHECKPOINT_SAVE = 10000  # Save checkpoints every epoch\n",
    "\n",
    "CONFIG_PATH = AUDIOCRAFT_REPO_DIR / \"config\" / \"dset\" / \"audio\" / \"all_data.yaml\"\n",
    "TRAIN_JSONL  = BASE_DIR / \"data\" / \"all_data\" / \"egs\" / \"train\" / \"data.jsonl\"\n",
    "VALID_JSONL  = BASE_DIR / \"data\" / \"all_data\" / \"egs\" / \"valid\" / \"data.jsonl\"\n",
    "\n",
    "print(NUM_WORKERS)\n",
    "print(CONFIG_PATH)\n",
    "print(TRAIN_JSONL)\n",
    "print(VALID_JSONL)\n",
    "print(AUDIOCRAFT_REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6aa36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export CUDA_VISIBLE_DEVICES=0,1\n",
    "export OMP_NUM_THREADS=4\n",
    "export MKL_NUM_THREADS=4\n",
    "export NCCL_P2P_DISABLE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224d461",
   "metadata": {},
   "source": [
    "## 1) Sanity checks\n",
    "Ensures dataset + config exist and CUDA is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, sys\n",
    "\n",
    "m = importlib.import_module(\"audiocraft\")\n",
    "\n",
    "print(\"Module object:\", m)\n",
    "print(\"m.__file__:\", getattr(m, \"__file__\", None))\n",
    "print(\"m.__path__:\", list(getattr(m, \"__path__\", [])))  # package dirs (if it's a package)\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.path (top 20):\")\n",
    "print(\"\\n\".join(sys.path[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcaafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "missing = [p for p in [CONFIG_PATH, TRAIN_JSONL, VALID_JSONL] if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing artifacts: {missing}. Run Notebook A first.\")\n",
    "\n",
    "importlib.import_module(\"audiocraft\")\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"CUDA is required for this run. Check your RunPod GPU setup.\")\n",
    "\n",
    "print(\"All sanity checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3c8ed",
   "metadata": {},
   "source": [
    "## 2) Run Dora training (compression/debug)\n",
    "Uses `%%bash` so it can be re-run easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b12ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import signal\n",
    "import subprocess\n",
    "import atexit\n",
    "\n",
    "# ---- Keep a handle to the currently running process (across cell reruns) ----\n",
    "try:\n",
    "    _DORA_PROC\n",
    "except NameError:\n",
    "    _DORA_PROC = None\n",
    "\n",
    "def _kill_proc_tree(proc: subprocess.Popen, timeout=10):\n",
    "    \"\"\"Terminate a process group (best for dora/ddp) safely.\"\"\"\n",
    "    if proc is None:\n",
    "        return\n",
    "    if proc.poll() is not None:\n",
    "        return  # already exited\n",
    "\n",
    "    try:\n",
    "        # Kill the whole process group\n",
    "        pgid = os.getpgid(proc.pid)\n",
    "        os.killpg(pgid, signal.SIGTERM)\n",
    "    except ProcessLookupError:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        proc.wait(timeout=timeout)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        try:\n",
    "            pgid = os.getpgid(proc.pid)\n",
    "            os.killpg(pgid, signal.SIGKILL)\n",
    "        except ProcessLookupError:\n",
    "            pass\n",
    "\n",
    "def _on_exit():\n",
    "    global _DORA_PROC\n",
    "    _kill_proc_tree(_DORA_PROC)\n",
    "    _DORA_PROC = None\n",
    "\n",
    "atexit.register(_on_exit)\n",
    "\n",
    "# ---- Pass Python variables to environment ----\n",
    "env = os.environ.copy()\n",
    "env[\"AUDIOCRAFT_TEAM\"] = \"default\"\n",
    "env[\"AUDIOCRAFT_DORA_DIR\"] = str(EXPERIMENTS_DIR)\n",
    "env[\"USER\"] = env.get(\"USER\", \"root\")\n",
    "env[\"PYTHONWARNINGS\"] = \"ignore::FutureWarning,ignore::UserWarning\"\n",
    "\n",
    "# ---- If a previous run is still alive, kill it before starting a new one ----\n",
    "_kill_proc_tree(_DORA_PROC)\n",
    "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
    "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={BATCH_SIZE}, num_workers={NUM_WORKERS}\")\n",
    "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
    "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}\")\n",
    "print(f\"Evaluate every: {EVALUATE_EVERY}\")\n",
    "print(f\"Autocast: {AUTOCAST}\")\n",
    "print(f\"Generate every: {GENERATE_EVERY}\")\n",
    "print(f\"Num threads: {NUM_THREADS}\")\n",
    "print(f\"dataset.generate.batch_size: {DATASET_BATCH_SIZE}\")\n",
    "print(f\"MP start method: {MP_START_METHOD}\")\n",
    "print(f\"Checkpoint save every: {CHECKPOINT_SAVE}\")\n",
    "\n",
    "# ---- Build the command as a list (avoid shell=True) ----\n",
    "cmd = [\n",
    "    \"python\", \"-m\", \"dora\", \"run\", \"-d\",\n",
    "    f\"solver={SOLVER}\",\n",
    "    f\"dset={DSET}\",\n",
    "    f\"dataset.segment_duration={SEGMENT_SECONDS}\",\n",
    "    f\"dataset.batch_size={BATCH_SIZE}\",\n",
    "    f\"dataset.generate.batch_size={DATASET_BATCH_SIZE}\",\n",
    "    f\"dataset.num_workers={NUM_WORKERS}\",\n",
    "    f\"optim.updates_per_epoch={UPDATES_PER_EPOCH}\",\n",
    "    f\"dataset.valid.num_samples={VALID_NUM_SAMPLES}\",\n",
    "    f\"generate.every={GENERATE_EVERY}\",\n",
    "    f\"evaluate.every={EVALUATE_EVERY}\",\n",
    "    f\"autocast={str(AUTOCAST).lower()}\",\n",
    "    f\"num_threads={NUM_THREADS}\",\n",
    "    f\"mp_start_method={MP_START_METHOD}\",\n",
    "    f\"checkpoint.save_every={CHECKPOINT_SAVE}\",\n",
    "    \n",
    "]\n",
    "#f\"dataset.num_samples={DATASET_NUM_SAMPLES}\",\n",
    "print(\"Launching:\", \" \".join(shlex.quote(x) for x in cmd))\n",
    "print(\"Dora dir:\", env[\"AUDIOCRAFT_DORA_DIR\"])\n",
    "\n",
    "# ---- Start in the repo directory + new process group so we can kill all workers ----\n",
    "_DORA_PROC = subprocess.Popen(\n",
    "    cmd,\n",
    "    cwd=str(AUDIOCRAFT_REPO_DIR),\n",
    "    env=env,\n",
    "    start_new_session=True,   # <-- creates a new process group/session\n",
    "    stdout=None,\n",
    "    stderr=None,\n",
    ")\n",
    "\n",
    "# Optional: wait for completion (Ctrl-C will stop this cell; atexit will still clean up on kernel exit)\n",
    "try:\n",
    "    rc = _DORA_PROC.wait()\n",
    "    if rc != 0:\n",
    "        raise RuntimeError(f\"Dora exited with code {rc}\")\n",
    "finally:\n",
    "    _kill_proc_tree(_DORA_PROC)\n",
    "    _DORA_PROC = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Capture XP id and logs path\n",
    "Finds the most recent Dora experiment under `/workspace/experiments/audiocraft/xps/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
    "xp_root.mkdir(parents=True, exist_ok=True)\n",
    "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "if not xp_dirs:\n",
    "    raise FileNotFoundError(\"No Dora runs found yet. Re-run the training cell above.\")\n",
    "\n",
    "latest = xp_dirs[-1]\n",
    "print(\"XP id:\", latest.name)\n",
    "print(\"Logs dir:\", latest)\n",
    "sample_logs = list(latest.glob(\"**/*.log\"))[:5]\n",
    "print(\"Sample log files:\")\n",
    "for lf in sample_logs:\n",
    "    print(\" •\", lf.relative_to(latest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Post-run validation\n",
    "Checks for artifacts/logs inside the XP directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
    "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "latest = xp_dirs[-1]\n",
    "\n",
    "checkpoints = list(latest.rglob(\"*.pt\"))\n",
    "logs = list(latest.rglob(\"*.log\"))\n",
    "\n",
    "print({\n",
    "    \"xp_id\": latest.name,\n",
    "    \"num_checkpoints\": len(checkpoints),\n",
    "    \"num_logs\": len(logs),\n",
    "    \"log_sample\": [p.relative_to(latest) for p in logs[:3]],\n",
    "})\n",
    "if logs:\n",
    "    tail_path = logs[0]\n",
    "    print(\"\\nTail of\", tail_path.name)\n",
    "    print(\"================\")\n",
    "    print(\"\".join(tail_path.read_text().splitlines(True)[-20:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Optional quick re-run\n",
    "Tweak batch size/workers without editing previous cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Quick re-run with adjusted batch size\n",
    "env = os.environ.copy()\n",
    "env['AUDIOCRAFT_TEAM'] = 'default'\n",
    "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
    "env['USER'] = env.get('USER', 'root')\n",
    "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
    "\n",
    "# Override batch size for this run\n",
    "alt_batch_size = 4\n",
    "\n",
    "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
    "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={alt_batch_size}, num_workers={NUM_WORKERS}\")\n",
    "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
    "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}, evaluate.every={EVALUATE_EVERY}, generate.every={GENERATE_EVERY}\")\n",
    "\n",
    "cmd = f\"\"\"\n",
    "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
    "python -m dora run \\\n",
    "  solver={SOLVER} \\\n",
    "  dset={DSET} \\\n",
    "  dataset.segment_duration={SEGMENT_SECONDS} \\\n",
    "  dataset.batch_size={alt_batch_size} \\\n",
    "  dataset.num_workers={NUM_WORKERS} \\\n",
    "  optim.updates_per_epoch={UPDATES_PER_EPOCH} \\\n",
    "  dataset.valid.num_samples={VALID_NUM_SAMPLES} \\\n",
    "  generate.every={GENERATE_EVERY} \\\n",
    "  evaluate.every={EVALUATE_EVERY}\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85608c2",
   "metadata": {},
   "source": [
    "## 6) Test model\n",
    "Test a completed model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /workspace/audiocraft\n",
    "\n",
    "python -m venv .venv-ac --system-site-packages\n",
    "source .venv-ac/bin/activate\n",
    "\n",
    "python -m pip install -U pip wheel setuptools\n",
    "python -m pip install -U xformers ipykernel\n",
    "python -m pip install -e .\n",
    "python -m ipykernel install --user --name audiocraft-ac --display-name \"Python (audiocraft-ac)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from audiocraft.solvers import CompressionSolver\n",
    "\n",
    "# IMPORTANT: this must point at the same dora dir used during training\n",
    "# (your logs looked like: /workspace/experiments/audiocraft/xps/<SIG>)\n",
    "os.environ[\"AUDIOCRAFT_DORA_DIR\"] = \"/workspace/experiments/audiocraft\"\n",
    "\n",
    "sig = \"550e2fc2\"  # <-- replace with your XP signature from the logs\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CompressionSolver.model_from_checkpoint(f\"//sig/{sig}\", device=device)\n",
    "print(\"Loaded:\", type(model), \"sr=\", model.sample_rate, \"channels=\", model.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf29cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# Load any WAV/MP3\n",
    "wav_path = \"/workspace/data/test.wav\"  # <-- your file\n",
    "wav, sr = torchaudio.load(wav_path)   # wav: [C, T]\n",
    "\n",
    "# Force mono if needed\n",
    "if wav.shape[0] > 1:\n",
    "    wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "# Resample to model SR\n",
    "target_sr = model.sample_rate\n",
    "if sr != target_sr:\n",
    "    wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
    "\n",
    "# Make a batch + move to device: [B, C, T]\n",
    "wav = wav.unsqueeze(0).to(device)\n",
    "\n",
    "# Optional: crop to 10s (matches your training segment_duration=10)\n",
    "max_len = int(10 * target_sr)\n",
    "wav = wav[..., :max_len]\n",
    "\n",
    "with torch.no_grad():\n",
    "    codes, scale = model.encode(wav)              # codes: discrete tokens  [oai_citation:3‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
    "    recon = model.decode(codes, scale=scale)      # recon: waveform  [oai_citation:4‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
    "\n",
    "# Save reconstructed audio\n",
    "out_path = \"/workspace/recon.wav\"\n",
    "torchaudio.save(out_path, recon.squeeze(0).cpu(), target_sr)\n",
    "print(\"Wrote:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
