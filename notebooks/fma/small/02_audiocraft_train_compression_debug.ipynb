{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — AudioCraft training (compression/debug)\n",
    "Run Dora training on the prepared `fma_small_mini` dataset and capture logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/root/workspace/audiocraft/config/dset/audio/fma_small_mini.yaml\n",
      "/root/workspace/data/fma_small_mini/egs/train/data.jsonl\n",
      "/root/workspace/data/fma_small_mini/egs/valid/data.jsonl\n",
      "/root/workspace/audiocraft\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Single switch for all paths (defaults to your new location)\n",
    "BASE_DIR = Path(os.environ.get(\"WORKSPACE_DIR\", \"/root/workspace\"))\n",
    "\n",
    "AUDIOCRAFT_REPO_DIR = BASE_DIR / \"audiocraft\"\n",
    "EXPERIMENTS_DIR     = BASE_DIR / \"experiments\" / \"audiocraft\"\n",
    "\n",
    "DSET = \"audio/fma_small_mini\"\n",
    "SOLVER = \"compression/debug\"\n",
    "\n",
    "SEGMENT_SECONDS = 10\n",
    "# BATCH_SIZE = 64  # Increased from 8 to improve GPU utilization\n",
    "BATCH_SIZE = 8  # Increased from 8 to improve GPU utilization\n",
    "\n",
    "# Auto-pick workers: reduce to 4-6 to avoid CPU contention\n",
    "_cpu_count = os.cpu_count() or 32\n",
    "# NUM_WORKERS = min(16, max(8, _cpu_count // 4))   # 8–16 is usually the sweet spot\n",
    "# NUM_WORKERS = 16 # this worked well on v84 cpu\n",
    "NUM_WORKERS = 0 # this worked well on v84 cpu\n",
    "\n",
    "UPDATES_PER_EPOCH = 50\n",
    "VALID_NUM_SAMPLES = 30\n",
    "GENERATE_EVERY = 10\n",
    "EVALUATE_EVERY = 10\n",
    "AUTOCAST = True\n",
    "# NUM_THREADS = 16  # Set number of threads for PyTorch operations\n",
    "NUM_THREADS = 16  # Set number of threads for PyTorch operations\n",
    "#MP_START_METHOD = \"fork\" # Use 'fork' to reduce overhead on Linux systems\n",
    "#MP_START_METHOD = \"fork\" # Alternative method if issues arise with 'fork'\n",
    "MP_START_METHOD = \"spawn\" # Alternative method if issues arise with 'fork'\n",
    "DATASET_BATCH_SIZE = 2 # Batch size for multi gpu setup\n",
    "\n",
    "\n",
    "\n",
    "CONFIG_PATH = AUDIOCRAFT_REPO_DIR / \"config\" / \"dset\" / \"audio\" / \"fma_small_mini.yaml\"\n",
    "TRAIN_JSONL  = BASE_DIR / \"data\" / \"fma_small_mini\" / \"egs\" / \"train\" / \"data.jsonl\"\n",
    "VALID_JSONL  = BASE_DIR / \"data\" / \"fma_small_mini\" / \"egs\" / \"valid\" / \"data.jsonl\"\n",
    "\n",
    "print(NUM_WORKERS)\n",
    "print(CONFIG_PATH)\n",
    "print(TRAIN_JSONL)\n",
    "print(VALID_JSONL)\n",
    "print(AUDIOCRAFT_REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6aa36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NVIDIA_TF32_OVERRIDE=1\n",
    "autocast=true autocast_dtype=bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224d461",
   "metadata": {},
   "source": [
    "## 1) Sanity checks\n",
    "Ensures dataset + config exist and CUDA is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2709bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module object: <module 'audiocraft' from '/root/workspace/audiocraft/audiocraft/__init__.py'>\n",
      "m.__file__: /root/workspace/audiocraft/audiocraft/__init__.py\n",
      "m.__path__: ['/root/workspace/audiocraft/audiocraft']\n",
      "sys.executable: /usr/bin/python\n",
      "sys.path (top 20):\n",
      "/usr/lib/python311.zip\n",
      "/usr/lib/python3.11\n",
      "/usr/lib/python3.11/lib-dynload\n",
      "\n",
      "/usr/local/lib/python3.11/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/usr/local/lib/python3.11/dist-packages/setuptools/_vendor\n",
      "/tmp/tmpwche8t9w\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys\n",
    "\n",
    "m = importlib.import_module(\"audiocraft\")\n",
    "\n",
    "print(\"Module object:\", m)\n",
    "print(\"m.__file__:\", getattr(m, \"__file__\", None))\n",
    "print(\"m.__path__:\", list(getattr(m, \"__path__\", [])))  # package dirs (if it's a package)\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.path (top 20):\")\n",
    "print(\"\\n\".join(sys.path[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcaafed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sanity checks passed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "missing = [p for p in [CONFIG_PATH, TRAIN_JSONL, VALID_JSONL] if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing artifacts: {missing}. Run Notebook A first.\")\n",
    "\n",
    "importlib.import_module(\"audiocraft\")\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"CUDA is required for this run. Check your RunPod GPU setup.\")\n",
    "\n",
    "print(\"All sanity checks passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ade7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NCCL_DEBUG=INFO\n",
    "export TORCH_DISTRIBUTED_DEBUG=DETAIL\n",
    "export NCCL_ASYNC_ERROR_HANDLING=1\n",
    "export NCCL_SOCKET_IFNAME=eth0\n",
    "export NCCL_P2P_DISABLE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# Build environment for Dora\n",
    "env = os.environ.copy()\n",
    "env['AUDIOCRAFT_TEAM'] = 'default'\n",
    "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
    "env['USER'] = env.get('USER', 'root')\n",
    "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
    "\n",
    "# Use the notebook variables so settings stay in sync\n",
    "cmd = f\"\"\"\n",
    "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
    "python -m dora run -d \\\n",
    "  solver=compression/debug dset=audio/fma_small_mini \\\n",
    "  dataset.segment_duration=10 \\\n",
    "  dataset.batch_size=32 \\\n",
    "  dataset.generate.batch_size=2 \\\n",
    "  dataset.num_workers=4 \\\n",
    "  optim.updates_per_epoch=50 \\\n",
    "  autocast=true \\\n",
    "  num_threads=1 \\\n",
    "  mp_start_method=fork \\\n",
    "  generate.every=null \\\n",
    "  evaluate.every=null\n",
    "  \"\"\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3c8ed",
   "metadata": {},
   "source": [
    "## 2) Run Dora training (compression/debug)\n",
    "Uses `%%bash` so it can be re-run easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b12ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config: dset=audio/fma_small_mini, solver=compression/debug\n",
      "Training params: segment_duration=10, batch_size=8, num_workers=0\n",
      "Optimizer: updates_per_epoch=50\n",
      "Validation: num_samples=30\n",
      "Evaluate every: 10\n",
      "Autocast: True\n",
      "Generate every: 10\n",
      "Num threads: 16\n",
      "dataset.generate.batch_size: 2\n",
      "MP start method: spawn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dora directory: /root/workspace/experiments/audiocraft\n",
      "\u001b[1mExecutor:\u001b[0m Starting 2 worker processes for DDP.\n",
      "Dora directory: /root/workspace/experiments/audiocraft\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - Distributed init: 0/2 (local 0) from env\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Instantiating solver CompressionSolver for XP 54032d67\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - All XP logs are stored in /root/workspace/experiments/audiocraft/xps/54032d67\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split train: /root/workspace/data/fma_small_mini/egs/train\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split valid: /root/workspace/data/fma_small_mini/egs/valid\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split evaluate: /root/workspace/data/fma_small_mini/egs/valid\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split generate: /root/workspace/data/fma_small_mini/egs/valid\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: 365c263301f13673720d0f350be14cef6ddaf70f\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Initializing EMA on the model with decay = 0.99 every 1 updates\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Model size: 0.23 M params\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Base memory usage, with model, grad and optim: 0.00 GB\u001b[0m\n",
      "[\u001b[36m01-26 18:25:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring weights and history.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Pass Python variables to bash environment\n",
    "env = os.environ.copy()\n",
    "env['AUDIOCRAFT_TEAM'] = 'default'\n",
    "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
    "env['USER'] = env.get('USER', 'root')\n",
    "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
    "\n",
    "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
    "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={BATCH_SIZE}, num_workers={NUM_WORKERS}\")\n",
    "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
    "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}\")\n",
    "print(f\"Evaluate every: {EVALUATE_EVERY}\")\n",
    "print(f\"Autocast: {AUTOCAST}\")\n",
    "print(f\"Generate every: {GENERATE_EVERY}\")\n",
    "print(f\"Num threads: {NUM_THREADS}\")\n",
    "print(f\"dataset.generate.batch_size: {DATASET_BATCH_SIZE}\")\n",
    "print(f\"MP start method: {MP_START_METHOD}\")\n",
    "\n",
    "cmd = f\"\"\"\n",
    "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
    "python -m dora run -d \\\n",
    "  solver={SOLVER} \\\n",
    "  dset={DSET} \\\n",
    "  dataset.segment_duration={SEGMENT_SECONDS} \\\n",
    "  dataset.batch_size={BATCH_SIZE} \\\n",
    "  dataset.generate.batch_size={DATASET_BATCH_SIZE} \\\n",
    "  dataset.num_workers={NUM_WORKERS} \\\n",
    "  optim.updates_per_epoch={UPDATES_PER_EPOCH} \\\n",
    "  dataset.valid.num_samples={VALID_NUM_SAMPLES} \\\n",
    "  generate.every={GENERATE_EVERY} \\\n",
    "  evaluate.every={EVALUATE_EVERY} \\\n",
    "  autocast={str(AUTOCAST).lower()} \\\n",
    "  num_threads={NUM_THREADS} \\\n",
    "  mp_start_method={MP_START_METHOD}\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610dcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Capture XP id and logs path\n",
    "Finds the most recent Dora experiment under `/workspace/experiments/audiocraft/xps/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
    "xp_root.mkdir(parents=True, exist_ok=True)\n",
    "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "if not xp_dirs:\n",
    "    raise FileNotFoundError(\"No Dora runs found yet. Re-run the training cell above.\")\n",
    "\n",
    "latest = xp_dirs[-1]\n",
    "print(\"XP id:\", latest.name)\n",
    "print(\"Logs dir:\", latest)\n",
    "sample_logs = list(latest.glob(\"**/*.log\"))[:5]\n",
    "print(\"Sample log files:\")\n",
    "for lf in sample_logs:\n",
    "    print(\" •\", lf.relative_to(latest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Post-run validation\n",
    "Checks for artifacts/logs inside the XP directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
    "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "latest = xp_dirs[-1]\n",
    "\n",
    "checkpoints = list(latest.rglob(\"*.pt\"))\n",
    "logs = list(latest.rglob(\"*.log\"))\n",
    "\n",
    "print({\n",
    "    \"xp_id\": latest.name,\n",
    "    \"num_checkpoints\": len(checkpoints),\n",
    "    \"num_logs\": len(logs),\n",
    "    \"log_sample\": [p.relative_to(latest) for p in logs[:3]],\n",
    "})\n",
    "if logs:\n",
    "    tail_path = logs[0]\n",
    "    print(\"\\nTail of\", tail_path.name)\n",
    "    print(\"================\")\n",
    "    print(\"\".join(tail_path.read_text().splitlines(True)[-20:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Optional quick re-run\n",
    "Tweak batch size/workers without editing previous cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Quick re-run with adjusted batch size\n",
    "env = os.environ.copy()\n",
    "env['AUDIOCRAFT_TEAM'] = 'default'\n",
    "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
    "env['USER'] = env.get('USER', 'root')\n",
    "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
    "\n",
    "# Override batch size for this run\n",
    "alt_batch_size = 4\n",
    "\n",
    "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
    "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={alt_batch_size}, num_workers={NUM_WORKERS}\")\n",
    "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
    "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}, evaluate.every={EVALUATE_EVERY}, generate.every={GENERATE_EVERY}\")\n",
    "\n",
    "cmd = f\"\"\"\n",
    "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
    "python -m dora run \\\n",
    "  solver={SOLVER} \\\n",
    "  dset={DSET} \\\n",
    "  dataset.segment_duration={SEGMENT_SECONDS} \\\n",
    "  dataset.batch_size={alt_batch_size} \\\n",
    "  dataset.num_workers={NUM_WORKERS} \\\n",
    "  optim.updates_per_epoch={UPDATES_PER_EPOCH} \\\n",
    "  dataset.valid.num_samples={VALID_NUM_SAMPLES} \\\n",
    "  generate.every={GENERATE_EVERY} \\\n",
    "  evaluate.every={EVALUATE_EVERY}\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85608c2",
   "metadata": {},
   "source": [
    "## 6) Test model\n",
    "Test a completed model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /workspace/audiocraft\n",
    "\n",
    "python -m venv .venv-ac --system-site-packages\n",
    "source .venv-ac/bin/activate\n",
    "\n",
    "python -m pip install -U pip wheel setuptools\n",
    "python -m pip install -U xformers ipykernel\n",
    "python -m pip install -e .\n",
    "python -m ipykernel install --user --name audiocraft-ac --display-name \"Python (audiocraft-ac)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from audiocraft.solvers import CompressionSolver\n",
    "\n",
    "# IMPORTANT: this must point at the same dora dir used during training\n",
    "# (your logs looked like: /workspace/experiments/audiocraft/xps/<SIG>)\n",
    "os.environ[\"AUDIOCRAFT_DORA_DIR\"] = \"/workspace/experiments/audiocraft\"\n",
    "\n",
    "sig = \"550e2fc2\"  # <-- replace with your XP signature from the logs\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CompressionSolver.model_from_checkpoint(f\"//sig/{sig}\", device=device)\n",
    "print(\"Loaded:\", type(model), \"sr=\", model.sample_rate, \"channels=\", model.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf29cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# Load any WAV/MP3\n",
    "wav_path = \"/workspace/data/test.wav\"  # <-- your file\n",
    "wav, sr = torchaudio.load(wav_path)   # wav: [C, T]\n",
    "\n",
    "# Force mono if needed\n",
    "if wav.shape[0] > 1:\n",
    "    wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "# Resample to model SR\n",
    "target_sr = model.sample_rate\n",
    "if sr != target_sr:\n",
    "    wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
    "\n",
    "# Make a batch + move to device: [B, C, T]\n",
    "wav = wav.unsqueeze(0).to(device)\n",
    "\n",
    "# Optional: crop to 10s (matches your training segment_duration=10)\n",
    "max_len = int(10 * target_sr)\n",
    "wav = wav[..., :max_len]\n",
    "\n",
    "with torch.no_grad():\n",
    "    codes, scale = model.encode(wav)              # codes: discrete tokens  [oai_citation:3‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
    "    recon = model.decode(codes, scale=scale)      # recon: waveform  [oai_citation:4‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
    "\n",
    "# Save reconstructed audio\n",
    "out_path = \"/workspace/recon.wav\"\n",
    "torchaudio.save(out_path, recon.squeeze(0).cpu(), target_sr)\n",
    "print(\"Wrote:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
