{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 — AudioCraft training (compression/debug)\n",
        "Run Dora training on the prepared `fma_large` dataset and capture logs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "AUDIOCRAFT_REPO_DIR = Path(\"/workspace/audiocraft\")\n",
        "EXPERIMENTS_DIR = Path(\"/workspace/experiments/audiocraft\")\n",
        "\n",
        "DSET = \"audio/fma_large\"\n",
        "SOLVER = \"compression/debug\"\n",
        "import os\n",
        "\n",
        "SEGMENT_SECONDS = 10\n",
        "BATCH_SIZE = 80  # Increased from 8 to improve GPU utilization\n",
        "# Auto-pick workers: reduce to 4-6 to avoid CPU contention\n",
        "_cpu_count = os.cpu_count() or 32\n",
        "NUM_WORKERS = min(16, max(8, _cpu_count // 4))   # 8–16 is usually the sweet spot\n",
        "UPDATES_PER_EPOCH = 50\n",
        "VALID_NUM_SAMPLES = 30\n",
        "GENERATE_EVERY = 2\n",
        "EVALUATE_EVERY = 2\n",
        "\n",
        "CONFIG_PATH = AUDIOCRAFT_REPO_DIR / \"config\" / \"dset\" / \"audio\" / \"fma_large.yaml\"\n",
        "TRAIN_JSONL = Path(\"/workspace/data/fma_large/egs/train/data.jsonl\")\n",
        "VALID_JSONL = Path(\"/workspace/data/fma_large/egs/valid/data.jsonl\")\n",
        "print(NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd86b79",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "# Rebuild xformers against current torch/Python/CUDA\n",
        "pip uninstall -y xformers || true\n",
        "pip install -U pip setuptools wheel ninja cmake\n",
        "# Limit parallel jobs if memory is tight; adjust as needed\n",
        "export MAX_JOBS=${MAX_JOBS:-10}\n",
        "pip install --no-build-isolation --no-binary xformers xformers==0.0.28.post3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Sanity checks\n",
        "Ensures dataset + config exist and CUDA is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import importlib\n",
        "\n",
        "missing = [p for p in [CONFIG_PATH, TRAIN_JSONL, VALID_JSONL] if not p.exists()]\n",
        "if missing:\n",
        "    raise FileNotFoundError(f\"Missing artifacts: {missing}. Run Notebook A first.\")\n",
        "\n",
        "importlib.import_module(\"audiocraft\")\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"CUDA is required for this run. Check your RunPod GPU setup.\")\n",
        "\n",
        "print(\"All sanity checks passed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Run Dora training (compression/debug)\n",
        "Uses `%%bash` so it can be re-run easily.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Pass Python variables to bash environment\n",
        "env = os.environ.copy()\n",
        "env['AUDIOCRAFT_TEAM'] = 'default'\n",
        "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
        "env['USER'] = env.get('USER', 'root')\n",
        "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
        "\n",
        "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
        "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={BATCH_SIZE}, num_workers={NUM_WORKERS}\")\n",
        "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
        "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}, evaluate.every={EVALUATE_EVERY}, generate.every={GENERATE_EVERY}\")\n",
        "\n",
        "cmd = f\"\"\"\n",
        "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
        "python -m dora run \\\n",
        "  solver={SOLVER} \\\n",
        "  dset={DSET} \\\n",
        "  dataset.segment_duration={SEGMENT_SECONDS} \\\n",
        "  dataset.batch_size={BATCH_SIZE} \\\n",
        "  dataset.num_workers={NUM_WORKERS} \\\n",
        "  optim.updates_per_epoch={UPDATES_PER_EPOCH} \\\n",
        "  dataset.valid.num_samples={VALID_NUM_SAMPLES} \\\n",
        "  generate.every={GENERATE_EVERY} \\\n",
        "  evaluate.every={EVALUATE_EVERY}\n",
        "\"\"\"\n",
        "\n",
        "subprocess.run(cmd, shell=True, check=True, env=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Capture XP id and logs path\n",
        "Finds the most recent Dora experiment under `/workspace/experiments/audiocraft/xps/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
        "xp_root.mkdir(parents=True, exist_ok=True)\n",
        "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if not xp_dirs:\n",
        "    raise FileNotFoundError(\"No Dora runs found yet. Re-run the training cell above.\")\n",
        "\n",
        "latest = xp_dirs[-1]\n",
        "print(\"XP id:\", latest.name)\n",
        "print(\"Logs dir:\", latest)\n",
        "sample_logs = list(latest.glob(\"**/*.log\"))[:5]\n",
        "print(\"Sample log files:\")\n",
        "for lf in sample_logs:\n",
        "    print(\" •\", lf.relative_to(latest))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Post-run validation\n",
        "Checks for artifacts/logs inside the XP directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "xp_root = EXPERIMENTS_DIR / \"xps\"\n",
        "xp_dirs = sorted([p for p in xp_root.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
        "latest = xp_dirs[-1]\n",
        "\n",
        "checkpoints = list(latest.rglob(\"*.pt\"))\n",
        "logs = list(latest.rglob(\"*.log\"))\n",
        "\n",
        "print({\n",
        "    \"xp_id\": latest.name,\n",
        "    \"num_checkpoints\": len(checkpoints),\n",
        "    \"num_logs\": len(logs),\n",
        "    \"log_sample\": [p.relative_to(latest) for p in logs[:3]],\n",
        "})\n",
        "if logs:\n",
        "    tail_path = logs[0]\n",
        "    print(\"\\nTail of\", tail_path.name)\n",
        "    print(\"================\")\n",
        "    print(\"\".join(tail_path.read_text().splitlines(True)[-20:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Optional quick re-run\n",
        "Tweak batch size/workers without editing previous cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Quick re-run with adjusted batch size\n",
        "env = os.environ.copy()\n",
        "env['AUDIOCRAFT_TEAM'] = 'default'\n",
        "env['AUDIOCRAFT_DORA_DIR'] = str(EXPERIMENTS_DIR)\n",
        "env['USER'] = env.get('USER', 'root')\n",
        "env['PYTHONWARNINGS'] = 'ignore::FutureWarning,ignore::UserWarning'\n",
        "\n",
        "# Override batch size for this run\n",
        "alt_batch_size = 4\n",
        "\n",
        "print(f\"Using config: dset={DSET}, solver={SOLVER}\")\n",
        "print(f\"Training params: segment_duration={SEGMENT_SECONDS}, batch_size={alt_batch_size}, num_workers={NUM_WORKERS}\")\n",
        "print(f\"Optimizer: updates_per_epoch={UPDATES_PER_EPOCH}\")\n",
        "print(f\"Validation: num_samples={VALID_NUM_SAMPLES}, evaluate.every={EVALUATE_EVERY}, generate.every={GENERATE_EVERY}\")\n",
        "\n",
        "cmd = f\"\"\"\n",
        "cd {AUDIOCRAFT_REPO_DIR} && \\\n",
        "python -m dora run \\\n",
        "  solver={SOLVER} \\\n",
        "  dset={DSET} \\\n",
        "  dataset.segment_duration={SEGMENT_SECONDS} \\\n",
        "  dataset.batch_size={alt_batch_size} \\\n",
        "  dataset.num_workers={NUM_WORKERS} \\\n",
        "  optim.updates_per_epoch={UPDATES_PER_EPOCH} \\\n",
        "  dataset.valid.num_samples={VALID_NUM_SAMPLES} \\\n",
        "  generate.every={GENERATE_EVERY} \\\n",
        "  evaluate.every={EVALUATE_EVERY}\n",
        "\"\"\"\n",
        "\n",
        "subprocess.run(cmd, shell=True, check=True, env=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a85608c2",
      "metadata": {},
      "source": [
        "## 6) Test model\n",
        "Test a completed model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28fa7556",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /workspace/audiocraft\n",
        "\n",
        "python -m venv .venv-ac --system-site-packages\n",
        "source .venv-ac/bin/activate\n",
        "\n",
        "python -m pip install -U pip wheel setuptools\n",
        "python -m pip install -U xformers ipykernel\n",
        "python -m pip install -e .\n",
        "python -m ipykernel install --user --name audiocraft-ac --display-name \"Python (audiocraft-ac)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16d9e69",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, torch\n",
        "from audiocraft.solvers import CompressionSolver\n",
        "\n",
        "# IMPORTANT: this must point at the same dora dir used during training\n",
        "# (your logs looked like: /workspace/experiments/audiocraft/xps/<SIG>)\n",
        "os.environ[\"AUDIOCRAFT_DORA_DIR\"] = \"/workspace/experiments/audiocraft\"\n",
        "\n",
        "sig = \"550e2fc2\"  # <-- replace with your XP signature from the logs\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CompressionSolver.model_from_checkpoint(f\"//sig/{sig}\", device=device)\n",
        "print(\"Loaded:\", type(model), \"sr=\", model.sample_rate, \"channels=\", model.channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf29cb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "# Load any WAV/MP3\n",
        "wav_path = \"/workspace/data/test.wav\"  # <-- your file\n",
        "wav, sr = torchaudio.load(wav_path)   # wav: [C, T]\n",
        "\n",
        "# Force mono if needed\n",
        "if wav.shape[0] > 1:\n",
        "    wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "# Resample to model SR\n",
        "target_sr = model.sample_rate\n",
        "if sr != target_sr:\n",
        "    wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
        "\n",
        "# Make a batch + move to device: [B, C, T]\n",
        "wav = wav.unsqueeze(0).to(device)\n",
        "\n",
        "# Optional: crop to 10s (matches your training segment_duration=10)\n",
        "max_len = int(10 * target_sr)\n",
        "wav = wav[..., :max_len]\n",
        "\n",
        "with torch.no_grad():\n",
        "    codes, scale = model.encode(wav)              # codes: discrete tokens  [oai_citation:3‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
        "    recon = model.decode(codes, scale=scale)      # recon: waveform  [oai_citation:4‡Facebook Research](https://facebookresearch.github.io/audiocraft/api_docs/audiocraft/models/encodec.html)\n",
        "\n",
        "# Save reconstructed audio\n",
        "out_path = \"/workspace/recon.wav\"\n",
        "torchaudio.save(out_path, recon.squeeze(0).cpu(), target_sr)\n",
        "print(\"Wrote:\", out_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}