{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b4d0e86",
      "metadata": {},
      "source": [
        "# 01b — FMA large mini downloader\n",
        "Sections 6–13 (download + preprocessing) split out from `01_fma_large_setup.ipynb`.\n",
        "Run the setup notebook first so system/Python deps and the AudioCraft repo are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20898701",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/workspace\")\n",
        "DATA_DIR = BASE_DIR / \"data\" / \"fma_large\"\n",
        "RAW_DIR = BASE_DIR / \"data\" / \"fma_raw\"\n",
        "AUDIOCRAFT_REPO_DIR = BASE_DIR / \"audiocraft\"\n",
        "EXPERIMENTS_DIR = BASE_DIR / \"experiments\" / \"audiocraft\"\n",
        "\n",
        "SEGMENT_SECONDS = 10\n",
        "TARGET_SR = 32000\n",
        "CHANNELS = 1\n",
        "TRAIN_RATIO = 0.9\n",
        "RANDOM_SEED = 42\n",
        "NUM_SAMPLES_TOTAL = None  # adjust to control how many source tracks to keep\n",
        "\n",
        "FMA_ARCHIVE_URLS = [\n",
        "    os.environ.get(\"FMA_SAMPLE_ARCHIVE_URL\"),\n",
        "    \"https://os.unil.cloud.switch.ch/fma/fma_large.zip\",\n",
        "    \"https://mirror.math.princeton.edu/pub/fma/fma_large.zip\",\n",
        "    \"https://huggingface.co/datasets/echonest/fma_large/resolve/main/fma_large.zip\",\n",
        "]\n",
        "FMA_ARCHIVE_URLS = [u for u in FMA_ARCHIVE_URLS if u]\n",
        "\n",
        "WAV_DIR = DATA_DIR / \"wav_32k_mono\"\n",
        "SEGMENTS_DIR = DATA_DIR / \"segments_10s\"\n",
        "MANIFEST_DIR = DATA_DIR / \"manifests\"\n",
        "EGS_TRAIN = DATA_DIR / \"egs\" / \"train\"\n",
        "EGS_VALID = DATA_DIR / \"egs\" / \"valid\"\n",
        "\n",
        "for p in (DATA_DIR, RAW_DIR, WAV_DIR, SEGMENTS_DIR, MANIFEST_DIR, EGS_TRAIN, EGS_VALID, EXPERIMENTS_DIR):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"Using URLs (in order):\", FMA_ARCHIVE_URLS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03fd04b6",
      "metadata": {},
      "source": [
        "## 6) Download a large FMA subset\n",
        "Downloads `fma_large.zip` (or a user-provided largeer archive) and extracts a limited number of MP3s.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7910d99",
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "archive_path = RAW_DIR / \"fma_large.zip\"\n",
        "mp3_root = RAW_DIR / \"fma_large\"\n",
        "\n",
        "def aria2_download(url: str, out_path: Path):\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    cmd = [\n",
        "        \"aria2c\",\n",
        "        \"-x\", \"16\",          # connections per server\n",
        "        \"-s\", \"16\",          # split count\n",
        "        \"-k\", \"1M\",          # chunk size\n",
        "        \"--file-allocation=none\",\n",
        "        \"--allow-overwrite=true\",\n",
        "        \"-o\", out_path.name,\n",
        "        \"-d\", str(out_path.parent),\n",
        "        url,\n",
        "    ]\n",
        "    print(\"Running:\", \" \".join(cmd))\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "if not any(mp3_root.rglob(\"*.mp3\")):\n",
        "    if not archive_path.exists():\n",
        "        if not FMA_ARCHIVE_URLS:\n",
        "            raise RuntimeError(\"Provide at least one FMA archive URL (set FMA_SAMPLE_ARCHIVE_URL)\")\n",
        "        last_err = None\n",
        "        for url in FMA_ARCHIVE_URLS:\n",
        "            try:\n",
        "                print(f\"Downloading {url} → {archive_path} (aria2c multi-conn)\")\n",
        "                aria2_download(url, archive_path)\n",
        "                break\n",
        "            except Exception as e:  # noqa: BLE001\n",
        "                last_err = e\n",
        "                print(f\"Failed {url}: {e}\")\n",
        "        if not archive_path.exists():\n",
        "            raise RuntimeError(f\"Download failed; last error: {last_err}\")\n",
        "\n",
        "    with zipfile.ZipFile(archive_path) as zf:\n",
        "        members = sorted([m for m in zf.namelist() if m.endswith(\".mp3\")])\n",
        "        if NUM_SAMPLES_TOTAL:\n",
        "            members = members[:NUM_SAMPLES_TOTAL]\n",
        "        print(f\"Extracting {len(members)} MP3s from archive…\")\n",
        "        for member in tqdm(members, desc=\"Extracting\", unit=\" files\"):\n",
        "            dest = RAW_DIR / member\n",
        "            if dest.exists():\n",
        "                continue\n",
        "            dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "            with zf.open(member) as src, open(dest, \"wb\") as dst:\n",
        "                dst.write(src.read())\n",
        "else:\n",
        "    print(\"MP3s already present; skipping download/extract.\")\n",
        "\n",
        "sampled_mp3s = sorted(mp3_root.rglob(\"*.mp3\"))\n",
        "print(\"MP3 files ready:\", len(sampled_mp3s))\n",
        "for name in sampled_mp3s[:5]:\n",
        "    print(\" •\", name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04bcb30f",
      "metadata": {},
      "source": [
        "## 7) Convert to mono 32k wav\n",
        "Uses ffmpeg; idempotent if WAVs already exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc789f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "WAV_DIR.mkdir(parents=True, exist_ok=True)\n",
        "mp3_files = sorted((RAW_DIR / \"fma_large\").rglob(\"*.mp3\"))\n",
        "\n",
        "for src in mp3_files:\n",
        "    dst = WAV_DIR / f\"{src.stem}.wav\"\n",
        "    if dst.exists():\n",
        "        continue\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
        "        \"-i\", str(src),\n",
        "        \"-ac\", str(CHANNELS),\n",
        "        \"-ar\", str(TARGET_SR),\n",
        "        \"-map_metadata\", \"-1\",\n",
        "        \"-vn\",\n",
        "        str(dst),\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "wav_files = sorted(WAV_DIR.glob(\"*.wav\"))\n",
        "print(\"WAV files ready:\", len(wav_files))\n",
        "for name in wav_files[:5]:\n",
        "    print(\" •\", name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebc1933",
      "metadata": {},
      "source": [
        "## 8) Segment into 10s chunks\n",
        "Segments each WAV into fixed-duration clips.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670b9843",
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import random\n",
        "\n",
        "SEGMENTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "wav_files = sorted(WAV_DIR.glob(\"*.wav\"))\n",
        "\n",
        "for wav in wav_files:\n",
        "    existing = list(SEGMENTS_DIR.glob(f\"{wav.stem}_seg_*.wav\"))\n",
        "    if existing:\n",
        "        continue\n",
        "    pattern = SEGMENTS_DIR / f\"{wav.stem}_seg_%03d.wav\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
        "        \"-i\", str(wav),\n",
        "        \"-f\", \"segment\",\n",
        "        \"-segment_time\", str(SEGMENT_SECONDS),\n",
        "        \"-reset_timestamps\", \"1\",\n",
        "        \"-map_metadata\", \"-1\",\n",
        "        str(pattern),\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "segments = sorted(SEGMENTS_DIR.glob(\"*.wav\"))\n",
        "print(\"Total segments:\", len(segments))\n",
        "\n",
        "def probe_duration(path: Path) -> float:\n",
        "    res = subprocess.run(\n",
        "        [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n",
        "            str(path),\n",
        "        ],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        check=True,\n",
        "    )\n",
        "    return float(res.stdout.strip())\n",
        "\n",
        "sample_check = random.sample(segments, k=min(5, len(segments))) if segments else []\n",
        "for s in sample_check:\n",
        "    print(s.name, \"→\", round(probe_duration(s), 3), \"s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db14350",
      "metadata": {},
      "source": [
        "## 9) Create train/valid manifests\n",
        "Deterministic split using `RANDOM_SEED` and `TRAIN_RATIO`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32874f76",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "segments = sorted(SEGMENTS_DIR.glob(\"*.wav\"))\n",
        "random.seed(RANDOM_SEED)\n",
        "random.shuffle(segments)\n",
        "\n",
        "split_idx = int(len(segments) * TRAIN_RATIO)\n",
        "train_files = segments[:split_idx]\n",
        "valid_files = segments[split_idx:] or segments[-1:]\n",
        "\n",
        "MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "with open(MANIFEST_DIR / \"train.jsonl\", \"w\") as f:\n",
        "    for p in train_files:\n",
        "        f.write(json.dumps({\"path\": str(p)}) + \"\\n\")\n",
        "with open(MANIFEST_DIR / \"valid.jsonl\", \"w\") as f:\n",
        "    for p in valid_files:\n",
        "        f.write(json.dumps({\"path\": str(p)}) + \"\\n\")\n",
        "\n",
        "print(\"Train/valid counts:\", len(train_files), len(valid_files))\n",
        "print(\"Sample manifest line:\")\n",
        "print((MANIFEST_DIR / \"train.jsonl\").read_text().splitlines()[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a14c6ce",
      "metadata": {},
      "source": [
        "## 10) Create `egs/train` and `egs/valid` symlinks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c16040",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for split, files in [(\"train\", train_files), (\"valid\", valid_files)]:\n",
        "    dest_dir = EGS_TRAIN if split == \"train\" else EGS_VALID\n",
        "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for path in files:\n",
        "        link = dest_dir / path.name\n",
        "        if link.exists() or link.is_symlink():\n",
        "            link.unlink()\n",
        "        link.symlink_to(path)\n",
        "\n",
        "print(\"egs/train count:\", len(list(EGS_TRAIN.glob(\"*.wav\"))))\n",
        "print(\"egs/valid count:\", len(list(EGS_VALID.glob(\"*.wav\"))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46fd84fb",
      "metadata": {},
      "source": [
        "## 11) Generate AudioCraft-native data.jsonl\n",
        "Adds `duration`, `sample_rate`, `channels` for each split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77163f8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "\n",
        "def probe(path: Path) -> dict:\n",
        "    res = subprocess.run(\n",
        "        [\n",
        "            \"ffprobe\", \"-v\", \"error\",\n",
        "            \"-select_streams\", \"a:0\",\n",
        "            \"-show_entries\", \"stream=sample_rate\", \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"json\",\n",
        "            str(path),\n",
        "        ],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        check=True,\n",
        "    )\n",
        "    info = json.loads(res.stdout)\n",
        "    duration = float(info[\"format\"][\"duration\"])\n",
        "    sample_rate = int(info[\"streams\"][0][\"sample_rate\"])\n",
        "    return {\"duration\": duration, \"sample_rate\": sample_rate, \"channels\": CHANNELS}\n",
        "\n",
        "for split, src_files, egs_dir in [\n",
        "    (\"train\", train_files, EGS_TRAIN),\n",
        "    (\"valid\", valid_files, EGS_VALID),\n",
        "]:\n",
        "    out_path = egs_dir / \"data.jsonl\"\n",
        "    with open(out_path, \"w\") as f:\n",
        "        for path in src_files:\n",
        "            payload = {\"path\": str(egs_dir / path.name)}\n",
        "            payload.update(probe(path))\n",
        "            f.write(json.dumps(payload) + \"\\n\")\n",
        "    print(f\"Wrote {split} data.jsonl →\", out_path)\n",
        "    with open(out_path) as f:\n",
        "        first_line = f.readline().strip()\n",
        "    print(\"First entry:\", first_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f037def5",
      "metadata": {},
      "source": [
        "## 12) Create Hydra dataset config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c817a32e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "mkdir -p /workspace/audiocraft/config/dset/audio\n",
        "cat > /workspace/audiocraft/config/dset/audio/fma_large.yaml <<'YAML'\n",
        "# @package __global__\n",
        "\n",
        "datasource:\n",
        "  max_sample_rate: 32000\n",
        "  max_channels: 1\n",
        "  train: /workspace/data/fma_large/egs/train\n",
        "  valid: /workspace/data/fma_large/egs/valid\n",
        "  evaluate: /workspace/data/fma_large/egs/valid\n",
        "  generate: /workspace/data/fma_large/egs/valid\n",
        "YAML\n",
        "ls -l /workspace/audiocraft/config/dset/audio/fma_large.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54a6332a",
      "metadata": {},
      "source": [
        "## 13) Ready-to-train checklist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b11ccba",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "print({\n",
        "    \"torch\": torch.__version__,\n",
        "    \"cuda\": torch.cuda.is_available(),\n",
        "    \"train_wavs\": len(list(EGS_TRAIN.glob(\"*.wav\"))),\n",
        "    \"valid_wavs\": len(list(EGS_VALID.glob(\"*.wav\"))),\n",
        "    \"train_jsonl\": EGS_TRAIN / \"data.jsonl\",\n",
        "    \"valid_jsonl\": EGS_VALID / \"data.jsonl\",\n",
        "    \"config\": Path('/workspace/audiocraft/config/dset/audio/fma_large.yaml'),\n",
        "    \"experiments_dir\": EXPERIMENTS_DIR,\n",
        "})\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
