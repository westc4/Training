{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "42d12e97",
      "metadata": {},
      "source": [
        "\n",
        "# 03 — AudioCraft generator training (MusicGen, unconditional debug)\n",
        "\n",
        "Stage 2: train the MusicGen token LM on the prepared FMA mini dataset, using the compression/codebook model trained in 02. Run this after 01b (dataset prep) and 02 (compression debug). No dataset download or prep happens here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15f83c62",
      "metadata": {},
      "source": [
        "## 1) Imports + shared paths/constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eced046",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUDIOCRAFT_REPO exists: True\n",
            "AUDIOCRAFT_DORA_DIR: /workspace/experiments/audiocraft\n",
            "ffmpeg: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Ensure writable caches for numba/joblib in container environments\n",
        "import os as _os\n",
        "_os.environ.setdefault('NUMBA_CACHE_DIR', '/tmp/numba_cache')\n",
        "_os.environ.setdefault('NUMBA_DISABLE_CACHING', '1')\n",
        "_os.environ.setdefault('JOBLIB_TEMP_FOLDER', '/tmp')\n",
        "\n",
        "import os, sys, subprocess, datetime, json\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "AUDIOCRAFT_REPO = Path(\"/workspace/audiocraft\")\n",
        "AUDIOCRAFT_DORA_DIR = Path(\"/workspace/experiments/audiocraft\")\n",
        "OUTPUT_DIR = Path(\"/workspace/Training/outputs/musicgen_uncond_debug\")\n",
        "\n",
        "DSET = \"audio/fma_small_mini\"\n",
        "CONFIG_PATH = Path(\"/workspace/Training/model_config/fma_small_mini.yaml\")\n",
        "EGS_DIR = Path(\"/workspace/data/fma_small_mini/egs\")\n",
        "EXPECTED_EGS = [EGS_DIR / \"train\", EGS_DIR / \"valid\"]\n",
        "\n",
        "# Debug-friendly hyperparams; tweak as needed\n",
        "SEGMENT_SECONDS = 10\n",
        "BATCH_SIZE = 4\n",
        "NUM_WORKERS = max(2, min(8, (os.cpu_count() or 8) // 4))\n",
        "UPDATES_PER_EPOCH = 30\n",
        "EPOCHS = 1\n",
        "GENERATE_EVERY = 10\n",
        "EVALUATE_EVERY = 10\n",
        "SEED = 1234\n",
        "GENERATE_SAMPLES = 2\n",
        "GENERATE_SECONDS = 8  # duration per sample for inference\n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"AUDIOCRAFT_REPO exists: {AUDIOCRAFT_REPO.exists()}\")\n",
        "print(f\"AUDIOCRAFT_DORA_DIR: {AUDIOCRAFT_DORA_DIR}\")\n",
        "try:\n",
        "    ffmpeg_ver = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
        "    first_line = (ffmpeg_ver.stdout or ffmpeg_ver.stderr).splitlines()[0]\n",
        "    print(\"ffmpeg:\", first_line)\n",
        "except FileNotFoundError:\n",
        "    print(\"ffmpeg not found (install via apt if you need extra formats)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2605e48e",
      "metadata": {},
      "source": [
        "## 2) Verify prerequisites exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "67fca3f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All prerequisite paths are present.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "missing = []\n",
        "for p in [CONFIG_PATH, AUDIOCRAFT_REPO, EGS_DIR]:\n",
        "    if not p.exists():\n",
        "        missing.append(str(p))\n",
        "\n",
        "missing_egs = [str(p) for p in EXPECTED_EGS if not p.exists()]\n",
        "if missing:\n",
        "    raise FileNotFoundError(f\"Missing required paths: {missing}. Run 01b to prepare data and 02 for codec training.\")\n",
        "if missing_egs:\n",
        "    raise FileNotFoundError(f\"Missing egs folders: {missing_egs}. Re-run 01b_fma_small_mini_downloader.ipynb.\")\n",
        "\n",
        "xps_root = AUDIOCRAFT_DORA_DIR / \"xps\"\n",
        "xps_root.mkdir(parents=True, exist_ok=True)\n",
        "print(\"All prerequisite paths are present.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9d6c37",
      "metadata": {},
      "source": [
        "## 3) Find the latest compression checkpoint automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e47d1ae8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using compression XP: 550e2fc2 | solver: compression\n",
            "Checkpoint: /workspace/experiments/audiocraft/xps/550e2fc2/checkpoint.th\n",
            "Timestamp: 2026-01-26 03:53:16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dora directory: /tmp/audiocraft_root\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compression meta: {'sample_rate': 16000, 'channels': 1, 'n_q': 32, 'cardinality': 1024, 'frame_rate': 50}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import yaml\n",
        "from audiocraft.solvers import CompressionSolver\n",
        "\n",
        "def read_solver_from_config(xp_dir: Path):\n",
        "    for candidate in [xp_dir / \"config.yaml\", xp_dir / \".hydra\" / \"config.yaml\", xp_dir / \"hydra-config.yaml\"]:\n",
        "        if candidate.exists():\n",
        "            try:\n",
        "                cfg = yaml.safe_load(candidate.read_text())\n",
        "            except Exception as exc:  # noqa: BLE001\n",
        "                print(f\"[warn] Could not parse {candidate}: {exc}\")\n",
        "                continue\n",
        "            solver = None\n",
        "            if isinstance(cfg, dict):\n",
        "                solver = cfg.get(\"solver\")\n",
        "                if solver is None and isinstance(cfg.get(\"xp\"), dict):\n",
        "                    solver = cfg[\"xp\"].get(\"solver\")\n",
        "            return solver, cfg\n",
        "    return None, None\n",
        "\n",
        "def find_xps(filter_keyword: Optional[str] = None):\n",
        "    xp_root = AUDIOCRAFT_DORA_DIR / \"xps\"\n",
        "    if not xp_root.exists():\n",
        "        return []\n",
        "    results = []\n",
        "    for xp in xp_root.iterdir():\n",
        "        if xp.is_dir():\n",
        "            solver, cfg = read_solver_from_config(xp)\n",
        "            solver_str = str(solver) if solver is not None else \"\"\n",
        "            if filter_keyword and filter_keyword not in solver_str:\n",
        "                continue\n",
        "            results.append((xp, solver_str))\n",
        "    results.sort(key=lambda t: t[0].stat().st_mtime)\n",
        "    return results\n",
        "\n",
        "def pick_checkpoint(xp_dir: Path):\n",
        "    priority = [\n",
        "        \"*best*.pt\", \"*best*.pth\", \"*best*.th\",\n",
        "        \"*latest*.pt\", \"*latest*.pth\", \"*latest*.th\",\n",
        "        \"checkpoint*.pt\", \"checkpoint*.pth\", \"checkpoint*.th\",\n",
        "    ]\n",
        "    def grab(patterns):\n",
        "        for pat in patterns:\n",
        "            files = sorted(xp_dir.rglob(pat), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "            if files:\n",
        "                return files[0]\n",
        "        return None\n",
        "    ckpt = grab(priority)\n",
        "    if ckpt is None:\n",
        "        pool = sorted(list(xp_dir.rglob(\"*.pt\")) + list(xp_dir.rglob(\"*.pth\")) + list(xp_dir.rglob(\"*.th\")),\n",
        "                      key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "        if pool:\n",
        "            ckpt = pool[0]\n",
        "    return ckpt\n",
        "\n",
        "compression_xps = find_xps(\"compression\")\n",
        "if not compression_xps:\n",
        "    raise FileNotFoundError(\"No compression Dora runs found. Run notebook 02_audiocraft_train_compression_debug.ipynb first.\")\n",
        "\n",
        "compression_dir, compression_solver_name = compression_xps[-1]\n",
        "compression_ckpt = pick_checkpoint(compression_dir)\n",
        "if compression_ckpt is None:\n",
        "    raise FileNotFoundError(f\"No checkpoint file found under {compression_dir}\")\n",
        "\n",
        "ckpt_time = datetime.datetime.fromtimestamp(compression_ckpt.stat().st_mtime)\n",
        "print(f\"Using compression XP: {compression_dir.name} | solver: {compression_solver_name}\")\n",
        "print(f\"Checkpoint: {compression_ckpt}\")\n",
        "print(f\"Timestamp: {ckpt_time:%Y-%m-%d %H:%M:%S}\")\n",
        "\n",
        "compression_model = CompressionSolver.model_from_checkpoint(str(compression_ckpt), device=\"cpu\")\n",
        "COMPRESSION_META = dict(\n",
        "    xp_dir=compression_dir,\n",
        "    ckpt_path=compression_ckpt,\n",
        "    sample_rate=compression_model.sample_rate,\n",
        "    channels=compression_model.channels,\n",
        "    n_q=getattr(compression_model, \"num_codebooks\", None),\n",
        "    cardinality=getattr(compression_model, \"cardinality\", None),\n",
        "    frame_rate=getattr(compression_model, \"frame_rate\", None),\n",
        ")\n",
        "if COMPRESSION_META[\"n_q\"] is None and hasattr(compression_model, \"quantizer\"):\n",
        "    COMPRESSION_META[\"n_q\"] = getattr(compression_model.quantizer, \"n_q\", None)\n",
        "print(\"Compression meta:\", {k: v for k, v in COMPRESSION_META.items() if k not in (\"xp_dir\", \"ckpt_path\")})\n",
        "del compression_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aa08316",
      "metadata": {},
      "source": [
        "## 4) Identify generator solver/config (unconditional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b46a7952",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available musicgen solvers: ['musicgen/debug.yaml', 'musicgen/default.yaml', 'musicgen/musicgen_base_32khz.yaml', 'musicgen/musicgen_melody_32khz.yaml', 'musicgen/musicgen_style_32khz.yaml']\n",
            "Available audiogen solvers: ['audiogen/audiogen_base_16khz.yaml', 'audiogen/debug.yaml', 'audiogen/default.yaml']\n",
            "Selected solver: musicgen/default (conditioner=none by default)\n",
            "Overrides for unconditional debug: {'model.lm.model_scale': 'xsmall', 'conditioner': 'none', 'generate.lm.use_sampling': False, 'generate.lm.prompted_samples': False, 'generate.lm.unprompted_samples': True, 'generate.lm.no_text_conditioning': True, 'generate.lm.top_k': 0, 'generate.lm.top_p': 0.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "solver_root = AUDIOCRAFT_REPO / \"config\" / \"solver\"\n",
        "musicgen_solvers = sorted([p.relative_to(solver_root).as_posix() for p in solver_root.glob(\"musicgen/*.yaml\")])\n",
        "audiogen_solvers = sorted([p.relative_to(solver_root).as_posix() for p in solver_root.glob(\"audiogen/*.yaml\")])\n",
        "print(\"Available musicgen solvers:\", musicgen_solvers)\n",
        "print(\"Available audiogen solvers:\", audiogen_solvers)\n",
        "\n",
        "# Choose a minimal, unconditional solver\n",
        "LM_SOLVER = \"musicgen/default\"\n",
        "if not (solver_root / (LM_SOLVER + \".yaml\")).exists():\n",
        "    raise FileNotFoundError(f\"Expected solver config missing: {LM_SOLVER}.yaml\")\n",
        "print(f\"Selected solver: {LM_SOLVER} (conditioner=none by default)\")\n",
        "\n",
        "LM_OVERRIDES = {\n",
        "    \"model.lm.model_scale\": \"xsmall\",\n",
        "    \"conditioner\": \"none\",\n",
        "    \"generate.lm.use_sampling\": False,\n",
        "    \"generate.lm.prompted_samples\": False,\n",
        "    \"generate.lm.unprompted_samples\": True,\n",
        "    \"generate.lm.no_text_conditioning\": True,\n",
        "    \"generate.lm.top_k\": 0,\n",
        "    \"generate.lm.top_p\": 0.0,\n",
        "}\n",
        "print(\"Overrides for unconditional debug:\", LM_OVERRIDES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d4eee4",
      "metadata": {},
      "source": [
        "## 5) Run a small debug training job via Dora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3c4916a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created solver config: debug_mini.yaml\n",
            "  • 32 codebooks × 1024 cardinality\n",
            "  • Mini transformer: 3 layers, 128 dim, 4 heads, causal=true\n",
            "  • 1 epoch × 30 updates, batch 4\n",
            "  • Checkpoints: save_last=true, generation: disabled during training\n",
            "\n",
            "Starting training...\n",
            "\n",
            "✓ Training completed!\n",
            "\n",
            "Key training logs:\n",
            "[\u001b01-26 04:45:35\u001b][\u001baudiocraft.solvers.compression\u001b][\u001bINFO\u001b] - Loading compression model from checkpoint: /workspace/experiments/audiocraft/xps/550e2fc2/checkpoint.th\u001b\n",
            "[\u001b01-26 04:45:35\u001b][\u001baudiocraft.utils.checkpoint\u001b][\u001bINFO\u001b] - Checkpoint loaded from /workspace/experiments/audiocraft/xps/550e2fc2/checkpoint.th\u001b\n",
            "[\u001b01-26 04:45:35\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Model size: 8.79 M params\u001b\n",
            "[\u001b01-26 04:45:43\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 3/30 | 0.51 it/sec | lr 1.00E-04 | grad_norm 7.665E-01 | grad_scale 65536.000 | ce 7.368 | ppl 1585.253\u001b\n",
            "[\u001b01-26 04:45:44\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 6/30 | 0.86 it/sec | lr 1.00E-04 | grad_norm 6.994E-01 | grad_scale 65536.000 | ce 7.265 | ppl 1430.171\u001b\n",
            "[\u001b01-26 04:45:44\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 9/30 | 1.19 it/sec | lr 1.00E-04 | grad_norm 7.621E-01 | grad_scale 65536.000 | ce 7.163 | ppl 1290.923\u001b\n",
            "[\u001b01-26 04:45:44\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 12/30 | 1.50 it/sec | lr 1.00E-04 | grad_norm 6.006E-01 | grad_scale 65536.000 | ce 7.119 | ppl 1235.018\u001b\n",
            "[\u001b01-26 04:45:44\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 15/30 | 1.78 it/sec | lr 1.00E-04 | grad_norm 6.251E-01 | grad_scale 65536.000 | ce 7.023 | ppl 1122.200\u001b\n",
            "[\u001b01-26 04:45:45\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 18/30 | 2.05 it/sec | lr 1.00E-04 | grad_norm 6.205E-01 | grad_scale 65536.000 | ce 6.939 | ppl 1032.255\u001b\n",
            "[\u001b01-26 04:45:45\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 21/30 | 2.29 it/sec | lr 1.00E-04 | grad_norm 6.731E-01 | grad_scale 65536.000 | ce 6.823 | ppl 919.534\u001b\n",
            "[\u001b01-26 04:45:45\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 24/30 | 2.52 it/sec | lr 1.00E-04 | grad_norm 6.281E-01 | grad_scale 65536.000 | ce 6.773 | ppl 873.896\u001b\n",
            "[\u001b01-26 04:45:46\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Train | Epoch 1 | 27/30 | 2.73 it/sec | lr 1.00E-04 | grad_norm 6.177E-01 | grad_scale 65536.000 | ce 6.715 | ppl 825.529\u001b\n",
            "[\u001b01-26 04:45:46\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - \u001b[1mTrain Summary | Epoch 1 | lr=1.00E-04 | grad_norm=6.651E-01 | grad_scale=65536.000 | ce=7.008 | ppl=1136.327 | duration=10.815\u001b\n",
            "[\u001b01-26 04:46:00\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 250/2500 | 17.72 it/sec | ce 6.604 | ppl 739.220\u001b\n",
            "[\u001b01-26 04:46:08\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 500/2500 | 22.85 it/sec | ce 6.610 | ppl 743.356\u001b\n",
            "[\u001b01-26 04:46:16\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 750/2500 | 25.42 it/sec | ce 6.604 | ppl 738.948\u001b\n",
            "[\u001b01-26 04:46:24\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 1000/2500 | 26.78 it/sec | ce 6.604 | ppl 739.132\u001b\n",
            "[\u001b01-26 04:46:31\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 1250/2500 | 27.75 it/sec | ce 6.610 | ppl 743.661\u001b\n",
            "[\u001b01-26 04:46:39\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 1500/2500 | 28.33 it/sec | ce 6.605 | ppl 739.527\u001b\n",
            "[\u001b01-26 04:46:47\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 1750/2500 | 28.84 it/sec | ce 6.606 | ppl 739.792\u001b\n",
            "[\u001b01-26 04:46:55\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 2000/2500 | 29.26 it/sec | ce 6.610 | ppl 743.444\u001b\n",
            "[\u001b01-26 04:47:02\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - Valid | Epoch 1 | 2250/2500 | 29.57 it/sec | ce 6.605 | ppl 739.624\u001b\n",
            "[\u001b01-26 04:47:10\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - \u001b[1mValid Summary | Epoch 1 | ce=6.607 | ppl=740.941 | duration=83.760\u001b\n",
            "[\u001b01-26 04:47:10\u001b][\u001bflashy.solver\u001b][\u001bINFO\u001b] - \u001b[1mEvaluate Summary | Epoch 1 | duration=0.000\u001b\n",
            "[\u001b01-26 04:48:35\u001b][\u001baudiocraft.utils.checkpoint\u001b][\u001bINFO\u001b] - Checkpoint saved to /workspace/experiments/audiocraft/xps/1ad5e091/checkpoint.th\u001b\n",
            "\n",
            "✓ Generator XP created: 1ad5e091\n",
            "  Location: /workspace/experiments/audiocraft/xps/1ad5e091\n"
          ]
        }
      ],
      "source": [
        "import shlex, subprocess\n",
        "import tempfile\n",
        "\n",
        "# Record existing generator runs to identify the new one after training\n",
        "pre_gen_dirs = {xp.name for xp, _ in find_xps(\"musicgen\")}\n",
        "\n",
        "env = os.environ.copy()\n",
        "env[\"AUDIOCRAFT_TEAM\"] = env.get(\"AUDIOCRAFT_TEAM\", \"default\")\n",
        "env[\"AUDIOCRAFT_DORA_DIR\"] = str(AUDIOCRAFT_DORA_DIR)\n",
        "env[\"USER\"] = env.get(\"USER\", \"root\")\n",
        "env[\"PYTHONWARNINGS\"] = \"ignore::FutureWarning,ignore::UserWarning\"\n",
        "env[\"NUMBA_CACHE_DIR\"] = \"/tmp/numba_cache\"\n",
        "env[\"NUMBA_DISABLE_CACHING\"] = \"1\"\n",
        "env[\"JOBLIB_TEMP_FOLDER\"] = \"/tmp\"\n",
        "\n",
        "# Create delay pattern for 32 codebooks\n",
        "delays = list(range(COMPRESSION_META['n_q']))  # [0, 1, 2, ..., 31]\n",
        "\n",
        "# Create a temporary solver config that extends musicgen/default with our specific values\n",
        "temp_solver_config = AUDIOCRAFT_REPO / \"config\" / \"solver\" / \"musicgen\" / \"debug_mini.yaml\"\n",
        "solver_config_content = f\"\"\"# @package __global__\n",
        "\n",
        "defaults:\n",
        "  - musicgen/default\n",
        "  - _self_\n",
        "\n",
        "sample_rate: {COMPRESSION_META['sample_rate']}\n",
        "channels: {COMPRESSION_META['channels']}\n",
        "compression_model_checkpoint: {COMPRESSION_META['ckpt_path']}\n",
        "\n",
        "lm_model: transformer_lm\n",
        "\n",
        "codebooks_pattern:\n",
        "  modeling: delay\n",
        "  delay:\n",
        "    delays: {delays}\n",
        "    flatten_first: 0\n",
        "    empty_initial: 0\n",
        "\n",
        "transformer_lm:\n",
        "  n_q: {COMPRESSION_META['n_q']}\n",
        "  card: {COMPRESSION_META['cardinality']}\n",
        "  dim: 128\n",
        "  num_heads: 4\n",
        "  hidden_scale: 2\n",
        "  num_layers: 3\n",
        "  causal: true\n",
        "  memory_efficient: true\n",
        "  bias_proj: false\n",
        "  bias_ff: false\n",
        "  bias_attn: false\n",
        "  norm_first: true\n",
        "  layer_scale: null\n",
        "  weight_init: gaussian\n",
        "  depthwise_init: current\n",
        "  zero_bias_init: true\n",
        "  attention_as_float32: false\n",
        "\n",
        "dataset:\n",
        "  segment_duration: {SEGMENT_SECONDS}\n",
        "  batch_size: {BATCH_SIZE}\n",
        "  num_workers: {NUM_WORKERS}\n",
        "  min_segment_ratio: 1.0\n",
        "\n",
        "generate:\n",
        "  every: null\n",
        "\n",
        "evaluate:\n",
        "  every: {EVALUATE_EVERY}\n",
        "\n",
        "checkpoint:\n",
        "  save_last: true\n",
        "  save_every: null\n",
        "\n",
        "optim:\n",
        "  epochs: {EPOCHS}\n",
        "  updates_per_epoch: {UPDATES_PER_EPOCH}\n",
        "\n",
        "tokens:\n",
        "  padding_with_special_token: false\n",
        "\n",
        "seed: {SEED}\n",
        "fsdp:\n",
        "  use: false\n",
        "logging:\n",
        "  log_tensorboard: false\n",
        "\"\"\"\n",
        "\n",
        "temp_solver_config.write_text(solver_config_content)\n",
        "print(f\"✓ Created solver config: {temp_solver_config.name}\")\n",
        "print(f\"  • {COMPRESSION_META['n_q']} codebooks × {COMPRESSION_META['cardinality']} cardinality\")\n",
        "print(f\"  • Mini transformer: 3 layers, 128 dim, 4 heads, causal=true\")\n",
        "print(f\"  • {EPOCHS} epoch × {UPDATES_PER_EPOCH} updates, batch {BATCH_SIZE}\")\n",
        "print(f\"  • Checkpoints: save_last=true, generation: disabled during training\")\n",
        "\n",
        "# Now run with the simplified command\n",
        "cmd = [\n",
        "    \"python\",\n",
        "    \"-m\", \"dora\", \"run\",\n",
        "    f\"solver=musicgen/debug_mini\",\n",
        "    f\"dset={DSET}\",\n",
        "    \"conditioner=none\",\n",
        "]\n",
        "print(f\"\\nStarting training...\")\n",
        "\n",
        "# Capture output\n",
        "result = subprocess.run(cmd, cwd=str(AUDIOCRAFT_REPO), env=env, check=False, capture_output=True, text=True)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"\\n❌ Training failed\")\n",
        "    print(\"\\n=== STDERR (last 8000 chars) ===\")\n",
        "    print(result.stderr[-8000:] if len(result.stderr) > 8000 else result.stderr)\n",
        "    if temp_solver_config.exists():\n",
        "        temp_solver_config.unlink()\n",
        "    raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)\n",
        "else:\n",
        "    # Show training progress\n",
        "    print(\"\\n✓ Training completed!\")\n",
        "    stderr_lines = result.stderr.splitlines()\n",
        "    if stderr_lines:\n",
        "        progress_lines = [l for l in stderr_lines if any(x in l for x in ['Train', 'Valid', 'Evaluate', 'Model size', 'checkpoint', 'Saving'])]\n",
        "        if progress_lines:\n",
        "            print(\"\\nKey training logs:\")\n",
        "            for line in progress_lines[-25:]:\n",
        "                # Strip ANSI codes for cleaner output\n",
        "                clean_line = line.replace('[36m', '').replace('[34m', '').replace('[32m', '').replace('[0m', '')\n",
        "                print(clean_line)\n",
        "\n",
        "# Clean up temp config\n",
        "if temp_solver_config.exists():\n",
        "    temp_solver_config.unlink()\n",
        "\n",
        "post_gen = find_xps(\"musicgen\")\n",
        "new_gen = [xp for xp, _ in post_gen if xp.name not in pre_gen_dirs]\n",
        "if not post_gen:\n",
        "    raise FileNotFoundError(\"No MusicGen runs found after training.\")\n",
        "GEN_XP_DIR = new_gen[-1] if new_gen else post_gen[-1][0]\n",
        "print(f\"\\n✓ Generator XP created: {GEN_XP_DIR.name}\")\n",
        "print(f\"  Location: {GEN_XP_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f41b2b",
      "metadata": {},
      "source": [
        "## 6) Locate generator checkpoint and generate audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a5ff61c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator checkpoint info:\n",
            "  XP: 1ad5e091\n",
            "  Checkpoint: checkpoint.th\n",
            "  Compression: checkpoint.th\n",
            "\n",
            "Loading model on cuda...\n",
            "Loading compression model from /workspace/experiments/audiocraft/xps/550e2fc2/checkpoint.th...\n",
            "Building LM model...\n",
            "Loading LM weights from checkpoint.th...\n",
            "✓ Model loaded: 400 tokens (8s at 50 Hz)\n",
            "\n",
            "Generating 2 samples...\n",
            "Saving audio files to /workspace/Training/outputs/musicgen_uncond_debug...\n",
            "\n",
            "✓ Generated samples:\n",
            "  generated_000.wav: 8.0s, RMS=0.0527, peak=0.1416\n",
            "  generated_001.wav: 8.0s, RMS=0.0527, peak=0.1416\n",
            "\n",
            "Summary:\n",
            "{\n",
            "  \"compression_checkpoint\": \"/workspace/experiments/audiocraft/xps/550e2fc2/checkpoint.th\",\n",
            "  \"generator_checkpoint\": \"/workspace/experiments/audiocraft/xps/1ad5e091/checkpoint.th\",\n",
            "  \"sample_rate\": 16000,\n",
            "  \"num_codebooks\": 32,\n",
            "  \"cardinality\": 1024,\n",
            "  \"generated\": [\n",
            "    {\n",
            "      \"path\": \"/workspace/Training/outputs/musicgen_uncond_debug/generated_000.wav\",\n",
            "      \"duration_sec\": 8.0,\n",
            "      \"rms\": 0.0527,\n",
            "      \"peak\": 0.1416\n",
            "    },\n",
            "    {\n",
            "      \"path\": \"/workspace/Training/outputs/musicgen_uncond_debug/generated_001.wav\",\n",
            "      \"duration_sec\": 8.0,\n",
            "      \"rms\": 0.0527,\n",
            "      \"peak\": 0.1416\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from audiocraft.solvers import CompressionSolver\n",
        "from audiocraft.utils import checkpoint\n",
        "from audiocraft.models.builders import get_lm_model\n",
        "import torch, torchaudio\n",
        "import omegaconf\n",
        "\n",
        "# Re-discover in case the session was reloaded\n",
        "musicgen_xps = find_xps(\"musicgen\")\n",
        "if not musicgen_xps:\n",
        "    musicgen_xps = find_xps(\"audiogen\")\n",
        "if not musicgen_xps:\n",
        "    raise FileNotFoundError(\"No generator XP found. Run the training cell above.\")\n",
        "\n",
        "GEN_XP_DIR = musicgen_xps[-1][0]\n",
        "GEN_CKPT = pick_checkpoint(GEN_XP_DIR)\n",
        "if GEN_CKPT is None:\n",
        "    raise FileNotFoundError(f\"No checkpoint found under {GEN_XP_DIR}\")\n",
        "\n",
        "print(\"Generator checkpoint info:\")\n",
        "print(f\"  XP: {GEN_XP_DIR.name}\")\n",
        "print(f\"  Checkpoint: {GEN_CKPT.name}\")\n",
        "print(f\"  Compression: {COMPRESSION_META['ckpt_path'].name}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nLoading model on {device}...\")\n",
        "\n",
        "try:\n",
        "    # Load the config\n",
        "    hydra_config = GEN_XP_DIR / \".hydra\" / \"config.yaml\"\n",
        "    if not hydra_config.exists():\n",
        "        raise FileNotFoundError(f\"Config not found at {hydra_config}\")\n",
        "    \n",
        "    cfg = omegaconf.OmegaConf.load(hydra_config)\n",
        "    cfg.device = device\n",
        "    \n",
        "    # Load compression model\n",
        "    print(f\"Loading compression model from {COMPRESSION_META['ckpt_path']}...\")\n",
        "    compression_model = CompressionSolver.model_from_checkpoint(COMPRESSION_META['ckpt_path'], device=device)\n",
        "    frame_rate = compression_model.frame_rate\n",
        "    \n",
        "    # Load LM model\n",
        "    print(f\"Building LM model...\")\n",
        "    lm_model = get_lm_model(cfg)\n",
        "    \n",
        "    # Load model state from checkpoint\n",
        "    print(f\"Loading LM weights from {GEN_CKPT.name}...\")\n",
        "    checkpoint_data = checkpoint.load_checkpoint(GEN_CKPT, is_sharded=False)\n",
        "    lm_model.load_state_dict(checkpoint_data['model'])\n",
        "    lm_model.to(device)\n",
        "    lm_model.eval()\n",
        "    \n",
        "    max_gen_len = int(GENERATE_SECONDS * frame_rate)\n",
        "    \n",
        "    print(f\"✓ Model loaded: {max_gen_len} tokens ({GENERATE_SECONDS}s at {frame_rate} Hz)\")\n",
        "    \n",
        "    print(f\"\\nGenerating {GENERATE_SAMPLES} samples...\")\n",
        "    with torch.no_grad():\n",
        "        tokens = lm_model.generate(\n",
        "            prompt=None,\n",
        "            num_samples=GENERATE_SAMPLES,\n",
        "            max_gen_len=max_gen_len,\n",
        "            use_sampling=False,\n",
        "            top_k=0,\n",
        "            top_p=0.0,\n",
        "        )\n",
        "        audio = compression_model.decode(tokens)\n",
        "    \n",
        "    audio = audio.detach().cpu()\n",
        "    sample_rate = int(compression_model.sample_rate)\n",
        "    saved = []\n",
        "    \n",
        "    print(f\"Saving audio files to {OUTPUT_DIR}...\")\n",
        "    for i in range(audio.shape[0]):\n",
        "        wav = audio[i]\n",
        "        if wav.dim() == 1:\n",
        "            wav = wav.unsqueeze(0)\n",
        "        out_path = OUTPUT_DIR / f\"generated_{i:03d}.wav\"\n",
        "        torchaudio.save(str(out_path), wav, sample_rate)\n",
        "        duration = wav.shape[-1] / sample_rate\n",
        "        rms = torch.sqrt(torch.mean(wav ** 2)).item()\n",
        "        peak = torch.max(torch.abs(wav)).item()\n",
        "        saved.append({\"path\": str(out_path), \"duration_sec\": round(duration, 2), \"rms\": round(rms, 4), \"peak\": round(peak, 4)})\n",
        "    \n",
        "    print(\"\\n✓ Generated samples:\")\n",
        "    for item in saved:\n",
        "        print(f\"  {Path(item['path']).name}: {item['duration_sec']}s, RMS={item['rms']}, peak={item['peak']}\")\n",
        "    \n",
        "    SUMMARY = {\n",
        "        \"compression_checkpoint\": str(COMPRESSION_META[\"ckpt_path\"]),\n",
        "        \"generator_checkpoint\": str(GEN_CKPT),\n",
        "        \"sample_rate\": sample_rate,\n",
        "        \"num_codebooks\": COMPRESSION_META[\"n_q\"],\n",
        "        \"cardinality\": COMPRESSION_META[\"cardinality\"],\n",
        "        \"generated\": saved,\n",
        "    }\n",
        "    print(\"\\nSummary:\")\n",
        "    print(json.dumps(SUMMARY, indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Generation failed: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6582f81",
      "metadata": {},
      "source": [
        "## 7) Minimal sanity evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eaeace70",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'saved' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m check_paths \u001b[38;5;241m=\u001b[39m [Path(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43msaved\u001b[49m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m check_paths:\n\u001b[1;32m      8\u001b[0m     wav, sr \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(p)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'saved' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import math\n",
        "import torchaudio\n",
        "\n",
        "check_paths = [Path(item[\"path\"]) for item in saved]\n",
        "for p in check_paths:\n",
        "    wav, sr = torchaudio.load(p)\n",
        "    duration = wav.shape[-1] / sr\n",
        "    finite = torch.isfinite(wav).all().item()\n",
        "    print(f\"{p.name}: sr={sr}, duration={duration:.2f}s, finite={finite}, rms={wav.pow(2).mean().sqrt().item():.4f}, peak={wav.abs().max().item():.4f}\")\n",
        "    if sr != sample_rate:\n",
        "        raise ValueError(f\"Unexpected sample rate in {p}: {sr} (expected {sample_rate})\")\n",
        "    if not finite:\n",
        "        raise ValueError(f\"NaNs detected in {p}\")\n",
        "print(\"Sanity checks complete.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11 (pod /usr/bin/python)",
      "language": "python",
      "name": "py311"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
